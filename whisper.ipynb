{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx329Vms5tCS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ6SNADO5xCU",
        "outputId": "512d58b0-e439-4f64-c6ee-50279c7409ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5HHGQyRJWmk",
        "outputId": "13ef443e-166b-45f9-94eb-d480b71debd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.286-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
            "  Downloading langsmith-0.0.35-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.286 langsmith-0.0.35 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKLe443jIqRX",
        "outputId": "36886cd9-c227-4d95-8137-33d81ac3bdb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[95m\u001b[1m\n",
            "*****EXPERIMENT*****\n",
            "\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "print(\"\\033[95m\\033[1m\" + \"\\n*****EXPERIMENT*****\\n\" + \"\\033[0m\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JT2w4EaWJWBJ"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkN2NRmPMs6v",
        "outputId": "cb17acbc-88c2-458c-952f-a9d193e7f97c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ],
      "source": [
        "pip install  pytube faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdM-6RRyMOUY"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import tempfile\n",
        "from moviepy.editor import *\n",
        "from pytube import YouTube\n",
        "from urllib.parse import urlparse,parse_qs\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfsiOYRBHtAU"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "# OPENAI_API_KEY=\"\"\n",
        "# openai.api_key=OPENAI_API_KEY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBM4ms6NadiK"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Gp7C0CMqOW",
        "outputId": "56fb8d70-3901-4636-bdbd-e54c533ac0d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-7xw1GZCNZQirwdaMWOlc91usDTkJA\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1694518734,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Hello! How can I assist you today?\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 8,\n",
            "    \"completion_tokens\": 9,\n",
            "    \"total_tokens\": 17\n",
            "  }\n",
            "}\n",
            "Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "# output = openai.ChatCompletion.create(\n",
        "#   model=\"gpt-3.5-turbo-0613\",\n",
        "#   messages=[{\"role\": \"user\", \"content\":\n",
        "#              \"hi\"}]\n",
        "# )\n",
        "\n",
        "# # Print out the whole output dictionary\n",
        "# print(output)\n",
        "\n",
        "# # Get the output text only\n",
        "# print(output['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXd7LIBTMAtD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRGek6SQNZqw",
        "outputId": "1e8a8d44-22a2-4806-e3c0-1c9cef5750e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-7xw1SzHhAVd2v9hL6ihzpfCJUBuJf\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1694518746,\n",
            "  \"model\": \"gpt-4-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Hello! How can I assist you today?\"\n",
            "      },\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 8,\n",
            "    \"completion_tokens\": 9,\n",
            "    \"total_tokens\": 17\n",
            "  }\n",
            "}\n",
            "Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "output = openai.ChatCompletion.create(\n",
        "  model=\"gpt-4\",\n",
        "  messages=[{\"role\": \"user\", \"content\":\n",
        "             \"hi\"}]\n",
        ")\n",
        "\n",
        "# Print out the whole output dictionary\n",
        "print(output)\n",
        "\n",
        "# Get the output text only\n",
        "print(output['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0WdqXjba6RC",
        "outputId": "911ce55e-ae0f-4aca-ba80-8cac29c810c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ahOrt_MUgbd"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnV_HiRfJqUq",
        "outputId": "3ff36689-a9e6-4151-85a7-674203d55d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter youtube url: https://www.youtube.com/watch?v=SwqusllMCnE\n",
            "/tmp/tmp4fxxrgfe\n",
            "/tmp/tmp4fxxrgfe/Nvidias NeMo Guardrails Full Walkthrough for Chatbots  AI.mp4\n",
            "MoviePy - Writing audio in /tmp/tmp4fxxrgfe/SwqusllMCnE.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "In the past year, we've seen the unparalleled adoption of chatbots across many industries. There hasn't really been an obvious technology that has been adopted and become so widespread so quickly as chatbots have. And in fact, according to a couple of reports from Gartner, they actually expect chatbots to be the primary communication channel for 25% of all organizations by 2027, which is not really that far away. This adoption is pretty amazing, but it's also dangerous. Chatbots make things up and they do very convincingly. And it's harder to give a chatbot guidelines like we would to an actual human. So if you have a human behind some chat, they've been trained on how to talk about your company, on what not to say, what to say, and to be polite and so on. It's a little more difficult with AI chatbots, particularly if we're just using the default approach of calling open AI. And when we want a chatbot to actually represent an organization, it's simply not enough. In short, we need something more to actually deploy conversational AI. To do that, we will be using Guardrails. Now, Guardrails is a kind of new library from NVIDIA. And the main focus of this library is to help us deploy chatbots safely. But there's actually a lot more that we can do with it. So we can use that for things like safety, for topical guidelines, but we can also use it for more advanced things. We can use it to build agents. We can use it in retrieval augments generation and naturally also to just define more deterministic dialogue where relevant. And honestly, if a company is going to production and deploying a chatbot without using Nemo Guardrails or some sort of alternative Guardrails system, I don't know. I'm just surprised that they are allowing it because things can go wrong very easily if you don't have these sort of things in place. So in most conversational AI systems at the moment, we kind of have this. We have this direct path between our conversational AI or our agent and our users. That's fine. But if something goes wrong, if the user begins asking about things that we don't really want our chatbot to respond to, like, for example, politics, or if our chatbot simply begins talking about something that we also don't want it to respond to or it begins responding in a way that doesn't really represent what we would like the chatbot to represent, we have an issue. There's no checks here. Nothing is happening. Now, we can improve the scenario a little bit through prompt engineering, but prompt engineering can only get us so far. There's always going to be cases where issues come up. So ideally, what we want is something in the middle here. We want what are called Guardrails, which can check what is being transferred between the user and the chatbot and react accordingly. So if the user begins talking about politics, we can create a pre-built message or we can instruct the bot to generate a message that says, sorry, I cannot talk about politics. Now, that is the core idea behind Guardrails. It's very simple. But what you can do with this is far more than just add some safety to our chatbots. What we are essentially doing here is we're creating rules, deterministic rules that say, okay, if the user begins talking, let's say about politics, we want to do something. So we can go over here and we can do some action. That action can be a safety measure or maybe in the case of our user is asking a question about maybe our product. So we have a product question here. If they do that, we don't really want to say, oh, sorry, I can't talk about our product, obviously, but we may want to do something different than just generate an answer. We may want to, for example, bring in some information from our database so that our chatbot can answer the question more accurately. So we do retrieve augmented generation in that case. We can also specify more deterministic dialogues. So maybe what we will see is that many users are kind of asking the same questions. They're going through the same dialogue paths. So if we have like common dialogues, we could create rails for them and they would allow us to create or catch the question. So the question would come over here and actually, rather than going to the bot here, we could specify a particular dialogue flow. So we can say, okay, given the user is asking about X, we should respond with a particular response. So we have a particular response. We can set that, we can write that ourselves, or we could actually ask the bot to write that response. And then from there, the dialogue could go multiple different ways until we reach some sort of final solution for our user. Now, this sort of deterministic dialogue flow is how chatbots used to work. Before chat GPT, there would be like a set path. You'd have to select the options within your dialogue. So the chatbot would introduce itself and it would say, what can I help you with? And you'd have to say, I have a problem with, and then it would give you like three options that you could choose from. Click on those and kind of go through almost like a path of dialogue. You wouldn't really be able to chat with the chatbot because it couldn't support that. That deterministic dialogue flow is actually useful, but it's restrictive. So we do kind of want that in some scenarios, particularly for those common dialogue flows that we can actually help with. But at the same time, we don't want to restrict our users to just those dialogue flows. We want the more flexible behavior of conversational AI like chat GPT. Now, another thing that we can actually use these guardrails for, which I've kind of hinted on a little bit with the rag example over here, is we can actually give it access to tools. Okay. So based on a particular question. So maybe our user says something like, okay, how is the weather today? An LLM is not going to be able to answer that question because it doesn't know what the weather is like today, but a LLM agent or conversational agent would be able to. And the reason that they can is because they have access to tools such as weather APIs. So the agent could identify this question is needing to use this weather API tool, and it would go to the weather API tool and it would say, you know, how is the weather? Give me the weather. And then it would formulate a response back to the user based on that. So we can also include tool usage in there. So let's take a look at a quick example of how all of this works in here on the left, we have the Nemo guardrails folder, and I have this config directory in here. I have a config and a topics.co. So co is a colang file, which we'll talk about a little more in a moment within the config, we are essentially specifying the configuration details for our chatbot, for our guardrails. So here I'm saying I want to use text of entry 0, 0, 3. We're using this model, just gets a little bit easier to set up with guardrails. But of course we can also use GPT 3.5 and also GPT 4, and actually other models as well from Hugging Face, Lama 2, and so on. So we have this config yaml file, and we also have this colang file. Now this colang file is where we set up the flow of a dialogue. So dialogue flow or the guardrails for particular topics or issues. So here I'm defining a few things. So we're expressing greetings from the user. We're also expressing a greeting from a bot. Now this is actually a hard-coded greeting. So when we use this, the chatbot will return specifically this text here, but we don't have to do that. Now we just have these, which is the greeting, and we'll talk a little bit more about the syntax soon. And then we also have a guardrail here. So we want to define our limits. If a user begins asking about politics, we want to say, okay, the bot's going to respond with, I'm a shopping assistant. I don't like the talk of politics. And sorry, I can't talk about politics. Actually, we can remove that. So that will be the response, this here. Now let's take a look at how we would actually use these files. So over in our terminal, we're going to navigate to this directory. So I'm going to cd documents, projects, examples, learn, generation, chatbots, nemo-guardrails, intra. So we've navigated to the directory in here. We just have that config directory that I mentioned before. So in order to use this, what we're going to do is first, we actually need to pip install guardrails. So pip install nemo-guardrails like so. And then we're going to do nemo-guardrails chat, and we set the config. So this will allow us to chat within our bash terminal. So we've now started our chat and we can say something. So I'm just going to say, hey there. And you see that we actually get these two messages. We get, hey there, and how are you doing? That is because within our colang file, we specified in a greeting flow that the bot will produce two responses. It will express a greeting and then it will express or ask how are you, which is exactly what it's doing here. Now, if we continue and let's ask something political. So can you tell me your thoughts on the president of the USA? We should see that this would block. So we can see it responds with, I'm a shopping assistant. I don't like to talk politics. How can I help you today? So we've successfully blocked that political question using the guardrails that we created in our colang file. Now let's talk a little bit about how that colang file was able to identify that this message that we created here should be blocked and that it belonged to that user as politics rail, despite us not specifying this exact question. So the way that this works is that we have our canonical forms and utterances. Just note that here, this is the canonical form and these are the utterances. And all of these are coming from the user. So we say define user, ask political. We give some examples. What would be political? And then we say define user, ask LLM. So that's a question about large language models. What would constitute a question about large language models? All of these sentences get taken to our embedding model. By default, that's a mini LM model and they get encoded into semantic web space. So then when the user comes along, they ask that question. Maybe they ask what I asked, what are your opinions about the president of the US or whatever I said. So you have that question coming from the user that goes into embedding model and then it creates, it would probably be over here, it creates a embedding. And then we can see these are most similar to the utterances that belong to the ask political canonical form. We see that here as well. So this is same visual. These are our political items. These are our LLM items or utterances. We have our user query. Are there any government build language models? Okay. So it's almost in between, but we're definitely asking about language models here. Hopefully the embedding model understand this. So the embedding model will take that and code it into the web space. And it will see that has more similarity with the utterances that come from the user ask LLM canonical form. So with that, we know that our query should activate a flow where user ask LLM is defined. Now there's a lot to talk about when it comes to guardrails, but I want to give just one example before we finish this video. In future videos, we will talk more about co-lang, which is the modeling language that guardrails uses and guardrails itself. So let's go through this one example. This is in Colab. So you can just follow along. We're going to first install Nemo guardrails and also opening AI. Now we will need to set our open AI API key. So we'll just import OS. We do OS environment, open AI API key. And in here, you'll just pass in your API key. Okay. And once that is done, the first thing that we want to do is define a co-lang file. So it's kind of what we saw before. It is that .co file. So I am going to define that here. We can either define it from file, or we can actually define it from a string in our code. So here I'm going to define it in a string in our code because we're, well, we're working within Colab. So in here, we have defined what are the three main types of blocks within co-lang. Those are the defined user blocks. So the user message blocks, the defined bot. So that is a bot message block. And if we come down here, we also have a flow block. So this is how we define the dialogue flow, right? So these here, they're our canonical forms. These are the utterances, and it is using those that we create that sort of vector space or populate that vector space. Then based on that vector space, we can decide when a user creates a message, which one of these should be activated. So if the user says, Hey, how are you? It will probably activate the user express greeting form. So actually in here, we can remove those because this is just a response from the bot again here as well. Okay, cool. So once we have initialized that, we can through the Python API initialize our rails. So we need to do from Nemo guard rails, import LLM rails, and also rails config. Okay. So the rails config is basically our configuration file. It takes our co-lang. And if we have a configuration YAML, it will take that as well and use that to initialize everything. Now, alongside our co-lang content, we also need the config content. So we'll just put YAML content, I think it's called. So YAML content equals, and this is where we just pass in our configuration details, which is basically just which model we want to use at least for now. There are more things that we can populate this with, but this is enough for what we're wanting to do here. Okay. So then we initialize our config with both of those. We want to write from content, which means we're loading these from within file. And we will have co-lang content. Yeah. Which is going to be with co-lang content and YAML content. Okay. That initializes our config. And from that, we can initialize our rails. So rails equals LLM rails, and we just pass in our config. Okay. So we run that. Okay. And then we can generate. So this is where we're actually talking with our rails. So within a notebook, we actually need to use async functions, just how it works, because guardrails is built to enable async. So we have to write this. And we'll just say like, hi there. We can run that and we get this response. We say, hey there, how are you doing? So again, we can see that the chat bot is going to bot express greeting and bot ask, how are you? Right. We'd see, hey there. And how are you doing? Which is exactly what we see here. Right. So we can try again with something, by the way, if you want to run this without async in like a Python file, you just run this. Okay. And we can say, I can't remember what the last question was. Yeah. What is your opinion on the president? Okay. Okay, cool. Let's run that. And we can see that activates that guardrail, which says I'm shopping assistant. I don't want to talk about politics. And then it says, how are you? How can I help today? Right. So that is a very simple example of how we would use guardrails. This really doesn't even start to scratch the surface of what we can actually do with guardrails. And there are many other examples that I will be sharing with you, like in the coming days and weeks, where we'll dive into a lot more detail. We'll take a look at the Kolang language, things like variables and actions. And on the guardrail side of things, we'll be diving into more detail on how we can sort of set up agents, essentially, how we can do retrieval augmentation and all of these other really cool things that guardrails allows us to do. For now, that's it for this introduction. So I hope this has all been useful and interesting, and I've covered a lot, but there is a lot to cover. So thank you very much for watching, and I will see you again in the next one.\n"
          ]
        }
      ],
      "source": [
        "def transcribe(file_path):\n",
        "  file_size=os.path.getsize(file_path)\n",
        "  file_mb=file_size/(1024*1024)\n",
        "  if file_mb<25:\n",
        "    with open(file_path, \"rb\") as audio_file:\n",
        "                  transcript=openai.Audio.transcribe('whisper-1',audio_file)\n",
        "    return transcript\n",
        "\n",
        "  else:\n",
        "        print(\"Please provide a smaller audio file (max 25mb).\")\n",
        "\n",
        "def div_segments():\n",
        "  return\n",
        "\n",
        "def main():\n",
        "  url=input(\"enter youtube url: \")\n",
        "  query=urlparse(url).query\n",
        "  param=parse_qs(query)\n",
        "  video_id = param[\"v\"][0]\n",
        "  # print(query,\" \",param,\" \",video_id)\n",
        "\n",
        "  with tempfile.TemporaryDirectory() as tempdir:\n",
        "    print(tempdir)\n",
        "    yt=YouTube(url)\n",
        "    audio_st=yt.streams.filter(only_audio=True).first()\n",
        "    audio_st.download(output_path=tempdir)\n",
        "\n",
        "    audio_path=os.path.join(tempdir,audio_st.default_filename)\n",
        "    print(audio_path)\n",
        "    audio_clip=AudioFileClip(audio_path)\n",
        "    audio_clip.write_audiofile(os.path.join(tempdir, f\"{video_id}.mp3\"))\n",
        "    audio_path=f\"{tempdir}/{video_id}.mp3\"\n",
        "    transcript = transcribe(audio_path)\n",
        "\n",
        "    # Delete the original audio file\n",
        "    os.remove(audio_path)\n",
        "    print(transcript.text)\n",
        "\n",
        "#     textsplitter=CharacterTextSplitter(chunk_size=256,chunk_overlap=0)\n",
        "#     text=textsplitter.split_text(transcript.text)\n",
        "\n",
        "#     store=FAISS.from_texts(text,OpenAIEmbeddings(),metadatas=[{\"source\": f\"Text chunk {i} of {len(text)}\"} for i in range(len(text))])\n",
        "#     faiss.write_index(store.index,\"docs.faiss\")\n",
        "#     llm=OpenAI(temperature=0)\n",
        "#     chain=RetrievalQAWithSourcesChain.from_chain_type(\n",
        "#         llm=llm, chain_type=\"stuff\", retriever=store.as_retriever()\n",
        "#     )\n",
        "#     while True:\n",
        "#         question = input(\"Question: \")\n",
        "#         answer = chain({\"question\": question}, return_only_outputs=True)\n",
        "#         print(\"Answer: \", answer[\"answer\"])\n",
        "#         #print(\"Sources: \", answer[\"sources\"])\n",
        "#         print(\"\\n\")\n",
        "\n",
        "\n",
        "# ## execute main\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f99xa_CWYzL",
        "outputId": "80c4e46b-a60a-4c60-93e0-db7a2ee5c285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter youtube url: https://www.youtube.com/watch?v=PFW47oSY9kM\n",
            "v=PFW47oSY9kM   {'v': ['PFW47oSY9kM']}   PFW47oSY9kM\n"
          ]
        }
      ],
      "source": [
        "# main()\n",
        "#trial 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8NAMplkQ6Ww",
        "outputId": "ed874dbe-d5f3-402a-e0ea-ae2bb9902de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter youtube url: https://www.youtube.com/watch?v=PFW47oSY9kM\n",
            "/tmp/tmp4z04eoa7\n",
            "/tmp/tmp4z04eoa7/first day of university vlog  productive & realistic day in my life.mp4\n",
            "MoviePy - Writing audio in /tmp/tmp4z04eoa7/PFW47oSY9kM.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Music Alarm clock beeping Music Hello people of the internet and welcome or welcome back to another video It is currently Wednesday September 6th and it is my first ever day of university I only have class in the afternoon. So I'm kind of taking this morning to slowly get ready and Prepare for my first day of university ever. I'm just doing my skincare right now So I thought I would kind of chat with you guys and update you on what's been going on while I do that. I Got a few questions in my last video about like what Exactly the difference between college and university is here and I do get that it can be definitely a little bit confusing So if you've been following my videos for a while, you know that I was just in college and I completed like a two-year program in Like arts but specialized in like cinema and communications Basically the way it works here in my province I don't know about the rest of Canada or in the States basically after high school. You usually graduate when you're like 1617 I think and then you go on either to do a specialization for three years and then you can work Immediately or you could go to a college for however many years in whatever program you want and then continue in university So that's what I did I went to college for two years But the program that I completed like is not one that you can really get a job in right after right out of school So that's why I'm now going to university to like continue studying that and get proper training For what I want to do. So as for the program that I am currently in I'm just starting My first semester as like a film major. I'm majoring in film production, which is so exciting like I Cannot wait. I know it's gonna be really challenging and I'm gonna be honest. I definitely feel a little intimidated, but I also Obviously want to get to know people I mean the first week is the perfect time to do this. I Look really pale right now, but that is my current skincare routine I am now gonna go downstairs and get started on breakfast and just like planning out my day. So let's do that I Just made myself some breakfast and while I eat that I'm gonna do a little bit of planning I just got this planner recently, but it has a weekly spread So I'm gonna write down the classes that I have coming up and all like my other Tasks and priorities for this week and I'm also gonna make a bit of a daily to-do list because I do have some things I want to get done today. So yeah, that's what I'm gonna do while I have my Lovely avocado toast and egg Been a long winter Chasing the train It's trying to get home to you my little dove It's only a splinter you'll not hear me complain You'll sleep late And I'll walk the dog Sunlight fills the windowsill Fruit grows sweet on the vine This old home is yours and mine It is basically time for me to go now I'm just gonna pack my backpack with everything I need so I'm gonna bring my laptop By the way, this laptop case is from loft and it is amazing I think it's so convenient and makes it really easy for me to bring my laptop to school So I'm gonna put that there and then I'm gonna bring my planner, of course I obviously need to bring my notebook as well I don't really know if we're gonna stay in a whole class or if this is just like an introduction But I'm still gonna bring something to take notes in just in case. I've got this pouch with my charger. I Have my hard drive SD card reader and all of those like tech things in here I'm just gonna bring a book because I have a long bus ride ahead of me So that'll give me something to do water, of course And then I'm also gonna bring a peach as a snack because it's a long class But I'm gonna get food before I get there because I plan on getting there a little bit early before my class So I can like walk around and situate myself. Yeah, I'm gonna pack my camera now and we can head out Oh Yeah, we thought a little we are Just sitting on below What you do by Just another way to You You I'm sorry for this like weird lighting situation. It is currently I wouldn't say like almost 9 p.m Yep, it's really not that late, but I got back from a walk with my friend Melina We kind of just spent some time catching up and hanging out outside Which was really nice to give you guys a bit of like a reflection on my first day I'm gonna be honest with you. It was Kind of brutal like I didn't expect that. I feel so drained after it yet. Here I am at 9 p.m. With a cup of lemon water ready to go to bed like I Feel so tired. My brain just wants to shut off I had planned on having like a productive evening doing a little bit of editing You know kind of like getting a few more tasks done before going to bed but honestly right now I Just gotta listen to my body and like rest because I was expecting going into it That I would feel more tired after my first day from Socializing but that was honestly not like bad at all I feel like what was more challenging for me was just like trying to understand the lecture As I mentioned I had film history which was very interesting but the teacher kind of just like dived right into the material and Technically, he had assigned a reading but he didn't make it available. So I Felt super unprepared. I was like rushing trying to understand everything that was Being said and then we also watched a film which was also like good and interesting But I'm gonna be honest that there were no subtitles and I am used to that so I didn't really understand What was being said and I know I'm not the only one because someone else in the class brought this up But yeah, it was just kind of like confusing and I wish I could like prepared more So I would have not like literally spent too much energy trying to understand everything That was being talked about but we live and we learn and now I know that next time I have that class I'll come more prepared with Probably a cup of tea to keep me awake because I was also getting pretty tired from sitting like obviously for a four hour long Lecture with only ten minutes as a break. Nonetheless, I'm grateful that I got to go to school and study something that I'm interested in I do look forward to like obviously having that class and learning things. I just wish things made more sense right now, but anyways Again, I like going into this video. I thought I was gonna have like a nice productive evening with you guys But I do think this is actually a good lesson because sometimes you just gotta listen to your body And take the rest that you need. I know right now if I tried to push through and be quote-unquote disciplined I would just feel terrible and I would have probably a really bad day tomorrow and feel exhausted So instead I'm just gonna take the rest that I need Do a little bit of journaling and spend some time away from my screens Because I don't want to go on any social media right now I want to just focus on me and I know that if I do that Then I will be much more prepared tomorrow to actually have a good day and get everything that I need to do done You\n"
          ]
        }
      ],
      "source": [
        "#trial 2\n",
        "#main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZE3qJcZQ7g8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
